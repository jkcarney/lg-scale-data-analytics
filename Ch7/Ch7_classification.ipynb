{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Most real-world machine learning problems use **supervised learning**. In supervised learning, the model will learn from a labeled training dataset. A target label is a variable that we want to predict. It is an extra piece of information that helps in making decisions or predictions.\n",
    "\n",
    "For example, which loan application is safe or risky, whether a patient suffers from a disease or not, house prices, and credit eligibility scores. These labels act as a supervisor or teacher for the learning process. **Classification** is one type of supervised learning algorithms. \n",
    "\n",
    "A classification problem has a categorical target variable, such as a loan application status as safe or risky, if a patient suffers from a disease, etc.\n",
    "\n",
    "In this chapter, we will learn two classification algorithms: **decision tree** and **K-Nearest Neighbor (KNN)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classification\n",
    "\n",
    "Decision tree builds classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node (e.g., Outlook) has two or more branches (e.g., Sunny, Overcast and Rainy). Leaf node (e.g., Play Golf) represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data. \n",
    "\n",
    "![](images/1.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core algorithm for building decision trees is called ID3 by J. R. Quinlan which employs a top-down, greedy search through the space of possible branches with no backtracking. ID3 uses **Entropy** and **Information Gain** to construct a decision tree.\n",
    "\n",
    "### Entropy\n",
    "A decision tree is built top-down from a root node and involves partitioning the data into subsets that contain instances with similar values (homogenous). ID3 algorithm uses entropy to calculate the homogeneity of a sample. If the sample is completely homogeneous the entropy is zero and if the sample is an equally divided it has entropy of one.\n",
    "\n",
    "To build a decision tree, we need to calculate two types of entropy using frequency tables as follows:\t\n",
    "\n",
    "* (a) Entropy using the frequency table of one attribute:\n",
    "![](images/2.jpg)\n",
    "\n",
    "* (b) Entropy using the frequency table of two attributes:\n",
    "!![](images/3.jpg)\n",
    "\n",
    "\n",
    "### Information Gain\n",
    "The information gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is all about finding attribute that returns the highest information gain (i.e., the most homogeneous branches).\n",
    "\n",
    "Step 1: Calculate entropy of the target. \n",
    "\n",
    "![](images/4.jpg)\n",
    "\n",
    "Step 2: The dataset is then split on the different attributes. The entropy for each branch is calculated. The resulting entropy is subtracted from the entropy before the split. The result is the Information Gain, or decrease in entropy. \n",
    "\n",
    "![](images/5.jpg)\n",
    "\n",
    "Step 3: Choose attribute with the largest information gain as the decision node, divide the dataset by its branches and repeat the same process on every branch.\n",
    "\n",
    "![](images/6.jpg)\n",
    "\n",
    "Step 4a: A branch with entropy of 0 is a leaf node.\n",
    "\n",
    "![](images/7.jpg)\n",
    "\n",
    "Step 4b: A branch with entropy more than 0 needs further splitting.\n",
    "\n",
    "Step 5: The ID3 algorithm is run recursively on the non-leaf branches, until all data is classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/9.jpg)\n",
    "\n",
    "## C4.5\n",
    "\n",
    "ID3 is the most common conventional decision tree algorithm but it has bottlenecks. Attributes must be nominal values, dataset must not include missing data, and finally the algorithm tend to fall into overfitting. Here, Ross Quinlan, inventor of ID3, made some improvements for these bottlenecks and created a new algorithm named C4.5. Now, the algorithm can create a more generalized models including continuous data and could handle missing data.\n",
    "\n",
    "Now, Let's look at this example.\n",
    "![](images/10.jpg)\n",
    "\n",
    "In ID3 algorithm, we’ve calculated information gains for each attribute. Here, we need to calculate gain ratios instead of gains.\n",
    "\n",
    "GainRatio(A) = Gain(A) / SplitInfo(A)\n",
    "\n",
    "SplitInfo(A) = $-∑ |D_j|/|D| * log_2|D_j|/|D|$\n",
    "\n",
    "e.g. Humidity Attribute\n",
    "\n",
    "As an exception, humidity is a continuous attribute. We need to convert continuous values to nominal ones. C4.5 proposes to perform binary split (Yes, it is always a binary tree) based on a threshold value. Threshold should be a value which offers maximum gain for that attribute. Let’s focus on humidity attribute. Firstly, we need to sort humidity values smallest to largest.\n",
    "\n",
    "![](images/11.jpg)\n",
    "\n",
    "### Check 65 as a threshold for humidity\n",
    "\n",
    "* Entropy(Humidity<=65) = – p(No) . log2p(No) – p(Yes) . log2p(Yes) = -(0/1).log2(0/1) – (1/1).log2(1/1) = 0\n",
    "\n",
    "* Entropy(Humidity>65) = -(5/13).log2(5/13) – (8/13).log2(8/13) =0.530 + 0.431 = 0.961\n",
    "\n",
    "* Info Gain(Decision, Humidity<>65) = 0.940 – (1/14).0 – (13/14).(0.961) = 0.048\n",
    "\n",
    "The statement above refers to that what would branch of decision tree be for less than or equal to 65, and greater than 65. It **does not** refer to that humidity is not equal to 65!\n",
    "\n",
    "* SplitInfo(Decision, Humidity<> 65) = -(1/14).log2(1/14) -(13/14).log2(13/14) = 0.371\n",
    "\n",
    "* GainRatio(Decision, Humidity<> 65) = 0.129\n",
    "\n",
    "### Check 70 as a threshold for humidity\n",
    "\n",
    "* Entropy(Decision|Humidity<=70) = – (1/4).log2(1/4) – (3/4).log2(3/4) = 0.811\n",
    "\n",
    "* Entropy(Decision|Humidity>70) =  – (4/10).log2(4/10) – (6/10).log2(6/10) = 0.970\n",
    "\n",
    "* Info Gain(Decision, Humidity<> 70) = 0.940 – (4/14).(0.811) – (10/14).(0.970) = 0.940 – 0.231 – 0.692 = 0.014\n",
    "\n",
    "* SplitInfo(Decision, Humidity<> 70) = -(4/14).log2(4/14) -(10/14).log2(10/14) = 0.863\n",
    "\n",
    "* GainRatio(Decision, Humidity<> 70) = 0.016\n",
    "\n",
    "### Check 75 as a threshold for humidity\n",
    "\n",
    "* Entropy(Decision|Humidity<=75) = – (1/5).log2(1/5) – (4/5).log2(4/5) = 0.721\n",
    "\n",
    "* Entropy(Decision|Humidity>75) = – (4/9).log2(4/9) – (5/9).log2(5/9) = 0.991\n",
    "\n",
    "* Gain(Decision, Humidity<> 75) = 0.940 – (5/14).(0.721) – (9/14).(0.991) = 0.940 – 0.2575 – 0.637 = 0.045\n",
    "\n",
    "* SplitInfo(Decision, Humidity<> 75) = -(5/14).log2(4/14) -(9/14).log2(10/14) = 0.940\n",
    "\n",
    "* GainRatio(Decision, Humidity<> 75) = 0.047\n",
    "\n",
    "I think I did enough computation here. I will skip the rest! C4.5 will find the max GainRatio and the corresponding threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Traning Data and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant     glucose          bp        skin     insulin         bmi  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age       label  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    " \n",
    "# read the dataset\n",
    "diabetes = pd.read_csv(\"diabetes.csv\")\n",
    " \n",
    "    \n",
    "# Show top 5-records\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in two parts: feature set and target label \n",
    "feature_set = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "features = diabetes[feature_set] \n",
    "target = diabetes.label\n",
    "\n",
    "# partition data into training and testing set \n",
    "from sklearn.model_selection import train_test_split\n",
    "feature_train,feature_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=1)\n",
    "#feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0\n",
      " 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 0 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0]\n",
      "Accuracy: 0.658008658008658\n",
      "Precision: 0.5416666666666666\n",
      "Recall: 0.4588235294117647\n",
      "F1-Score: 0.49681528662420377\n"
     ]
    }
   ],
   "source": [
    "# Import Decision Tree model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import metrics module for performance evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "# Create a Decision Tree classifier object\n",
    "clf = DecisionTreeClassifier()\n",
    " \n",
    "# Train the model using training dataset\n",
    "clf = clf.fit(feature_train,target_train)\n",
    " \n",
    "# Predict the response for test dataset\n",
    "predictions = clf.predict(feature_test)\n",
    "\n",
    "print(predictions)\n",
    " \n",
    "# Calculate model accuracy\n",
    "print(\"Accuracy:\",accuracy_score(target_test, predictions))\n",
    "# Calculate model precision\n",
    "print(\"Precision:\",precision_score(target_test, predictions))\n",
    "# Calculate model recall\n",
    "print(\"Recall:\",recall_score(target_test, predictions))\n",
    "# Calculate model f1 score\n",
    "print(\"F1-Score:\",f1_score(target_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(136.24761235955057, 210.645, 'X[4] <= 129.5\\ngini = 0.449\\nsamples = 537\\nvalue = [354, 183]'),\n",
       " Text(49.726264044943825, 197.055, 'X[2] <= 26.3\\ngini = 0.329\\nsamples = 357\\nvalue = [283, 74]'),\n",
       " Text(15.047191011235956, 183.465, 'X[2] <= 9.1\\ngini = 0.06\\nsamples = 97\\nvalue = [94, 3]'),\n",
       " Text(7.523595505617978, 169.875, 'X[4] <= 114.5\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(3.761797752808989, 156.285, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(11.285393258426968, 156.285, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(22.570786516853936, 169.875, 'X[6] <= 0.669\\ngini = 0.022\\nsamples = 91\\nvalue = [90, 1]'),\n",
       " Text(18.808988764044944, 156.285, 'gini = 0.0\\nsamples = 76\\nvalue = [76, 0]'),\n",
       " Text(26.332584269662924, 156.285, 'X[6] <= 0.705\\ngini = 0.124\\nsamples = 15\\nvalue = [14, 1]'),\n",
       " Text(22.570786516853936, 142.695, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(30.094382022471912, 142.695, 'gini = 0.0\\nsamples = 14\\nvalue = [14, 0]'),\n",
       " Text(84.40533707865168, 183.465, 'X[3] <= 27.5\\ngini = 0.397\\nsamples = 260\\nvalue = [189, 71]'),\n",
       " Text(48.90337078651686, 169.875, 'X[2] <= 45.4\\ngini = 0.243\\nsamples = 120\\nvalue = [103, 17]'),\n",
       " Text(41.379775280898876, 156.285, 'X[0] <= 7.0\\ngini = 0.212\\nsamples = 116\\nvalue = [102, 14]'),\n",
       " Text(37.61797752808989, 142.695, 'X[5] <= 12.0\\ngini = 0.201\\nsamples = 115\\nvalue = [102, 13]'),\n",
       " Text(33.8561797752809, 129.10500000000002, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(41.379775280898876, 129.10500000000002, 'X[6] <= 1.272\\ngini = 0.188\\nsamples = 114\\nvalue = [102, 12]'),\n",
       " Text(33.8561797752809, 115.515, 'X[2] <= 30.95\\ngini = 0.165\\nsamples = 110\\nvalue = [100, 10]'),\n",
       " Text(30.094382022471912, 101.925, 'gini = 0.0\\nsamples = 43\\nvalue = [43, 0]'),\n",
       " Text(37.61797752808989, 101.925, 'X[5] <= 53.0\\ngini = 0.254\\nsamples = 67\\nvalue = [57, 10]'),\n",
       " Text(24.45168539325843, 88.33500000000001, 'X[6] <= 0.264\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(20.689887640449438, 74.745, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(28.213483146067418, 74.745, 'X[4] <= 125.5\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(24.45168539325843, 61.155, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(31.975280898876406, 61.155, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(50.78426966292135, 88.33500000000001, 'X[6] <= 0.652\\ngini = 0.203\\nsamples = 61\\nvalue = [54, 7]'),\n",
       " Text(43.26067415730337, 74.745, 'X[1] <= 36.5\\ngini = 0.15\\nsamples = 49\\nvalue = [45, 4]'),\n",
       " Text(39.49887640449438, 61.155, 'X[5] <= 82.5\\ngini = 0.32\\nsamples = 20\\nvalue = [16, 4]'),\n",
       " Text(35.737078651685394, 47.565, 'X[2] <= 33.65\\ngini = 0.266\\nsamples = 19\\nvalue = [16, 3]'),\n",
       " Text(28.213483146067418, 33.974999999999994, 'X[4] <= 102.0\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(24.45168539325843, 20.38499999999999, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(31.975280898876406, 20.38499999999999, 'X[5] <= 66.0\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(28.213483146067418, 6.7949999999999875, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(35.737078651685394, 6.7949999999999875, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(43.26067415730337, 33.974999999999994, 'X[6] <= 0.458\\ngini = 0.142\\nsamples = 13\\nvalue = [12, 1]'),\n",
       " Text(39.49887640449438, 20.38499999999999, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(47.022471910112365, 20.38499999999999, 'X[5] <= 64.0\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(43.26067415730337, 6.7949999999999875, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(50.78426966292135, 6.7949999999999875, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(43.26067415730337, 47.565, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(47.022471910112365, 61.155, 'gini = 0.0\\nsamples = 29\\nvalue = [29, 0]'),\n",
       " Text(58.30786516853933, 74.745, 'X[1] <= 65.5\\ngini = 0.375\\nsamples = 12\\nvalue = [9, 3]'),\n",
       " Text(54.54606741573034, 61.155, 'gini = 0.0\\nsamples = 7\\nvalue = [7, 0]'),\n",
       " Text(62.06966292134832, 61.155, 'X[4] <= 115.0\\ngini = 0.48\\nsamples = 5\\nvalue = [2, 3]'),\n",
       " Text(58.30786516853933, 47.565, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(65.83146067415731, 47.565, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(48.90337078651686, 115.515, 'X[2] <= 29.5\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(45.14157303370787, 101.925, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(52.66516853932585, 101.925, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(45.14157303370787, 142.695, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(56.426966292134836, 156.285, 'X[1] <= 185.0\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(52.66516853932585, 142.695, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(60.188764044943824, 142.695, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(119.90730337078652, 169.875, 'X[6] <= 0.563\\ngini = 0.474\\nsamples = 140\\nvalue = [86, 54]'),\n",
       " Text(89.34269662921349, 156.285, 'X[4] <= 101.5\\ngini = 0.408\\nsamples = 98\\nvalue = [70, 28]'),\n",
       " Text(67.7123595505618, 142.695, 'X[5] <= 27.0\\ngini = 0.208\\nsamples = 34\\nvalue = [30, 4]'),\n",
       " Text(63.95056179775281, 129.10500000000002, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(71.47415730337079, 129.10500000000002, 'X[3] <= 42.5\\ngini = 0.165\\nsamples = 33\\nvalue = [30, 3]'),\n",
       " Text(67.7123595505618, 115.515, 'gini = 0.0\\nsamples = 23\\nvalue = [23, 0]'),\n",
       " Text(75.23595505617978, 115.515, 'X[4] <= 97.5\\ngini = 0.42\\nsamples = 10\\nvalue = [7, 3]'),\n",
       " Text(71.47415730337079, 101.925, 'X[2] <= 35.25\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(67.7123595505618, 88.33500000000001, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(75.23595505617978, 88.33500000000001, 'X[4] <= 96.0\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(71.47415730337079, 74.745, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(78.99775280898876, 74.745, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(78.99775280898876, 101.925, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(110.97303370786517, 142.695, 'X[5] <= 67.0\\ngini = 0.469\\nsamples = 64\\nvalue = [40, 24]'),\n",
       " Text(97.80674157303372, 129.10500000000002, 'X[5] <= 58.0\\ngini = 0.465\\nsamples = 19\\nvalue = [7, 12]'),\n",
       " Text(90.28314606741574, 115.515, 'X[2] <= 30.05\\ngini = 0.245\\nsamples = 7\\nvalue = [6, 1]'),\n",
       " Text(86.52134831460674, 101.925, 'X[3] <= 33.5\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(82.75955056179775, 88.33500000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(90.28314606741574, 88.33500000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(94.04494382022473, 101.925, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(105.3303370786517, 115.515, 'X[6] <= 0.425\\ngini = 0.153\\nsamples = 12\\nvalue = [1, 11]'),\n",
       " Text(101.5685393258427, 101.925, 'gini = 0.0\\nsamples = 11\\nvalue = [0, 11]'),\n",
       " Text(109.09213483146068, 101.925, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(124.13932584269664, 129.10500000000002, 'X[2] <= 43.1\\ngini = 0.391\\nsamples = 45\\nvalue = [33, 12]'),\n",
       " Text(120.37752808988765, 115.515, 'X[4] <= 102.5\\ngini = 0.337\\nsamples = 42\\nvalue = [33, 9]'),\n",
       " Text(116.61573033707866, 101.925, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(124.13932584269664, 101.925, 'X[2] <= 34.6\\ngini = 0.289\\nsamples = 40\\nvalue = [33, 7]'),\n",
       " Text(120.37752808988765, 88.33500000000001, 'X[3] <= 35.0\\ngini = 0.434\\nsamples = 22\\nvalue = [15, 7]'),\n",
       " Text(116.61573033707866, 74.745, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(124.13932584269664, 74.745, 'X[4] <= 123.5\\ngini = 0.492\\nsamples = 16\\nvalue = [9, 7]'),\n",
       " Text(120.37752808988765, 61.155, 'X[6] <= 0.375\\ngini = 0.426\\nsamples = 13\\nvalue = [9, 4]'),\n",
       " Text(116.61573033707866, 47.565, 'X[0] <= 6.5\\ngini = 0.298\\nsamples = 11\\nvalue = [9, 2]'),\n",
       " Text(112.85393258426967, 33.974999999999994, 'X[5] <= 85.0\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(109.09213483146068, 20.38499999999999, 'X[5] <= 75.0\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(105.3303370786517, 6.7949999999999875, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(112.85393258426967, 6.7949999999999875, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(116.61573033707866, 20.38499999999999, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(120.37752808988765, 33.974999999999994, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(124.13932584269664, 47.565, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(127.90112359550562, 61.155, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(127.90112359550562, 88.33500000000001, 'gini = 0.0\\nsamples = 18\\nvalue = [18, 0]'),\n",
       " Text(127.90112359550562, 115.515, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(150.47191011235955, 156.285, 'X[0] <= 8.5\\ngini = 0.472\\nsamples = 42\\nvalue = [16, 26]'),\n",
       " Text(146.71011235955058, 142.695, 'X[5] <= 87.0\\ngini = 0.5\\nsamples = 33\\nvalue = [16, 17]'),\n",
       " Text(142.94831460674158, 129.10500000000002, 'X[4] <= 97.0\\ngini = 0.477\\nsamples = 28\\nvalue = [11, 17]'),\n",
       " Text(139.1865168539326, 115.515, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(146.71011235955058, 115.515, 'X[4] <= 116.5\\ngini = 0.413\\nsamples = 24\\nvalue = [7, 17]'),\n",
       " Text(139.1865168539326, 101.925, 'X[6] <= 1.395\\ngini = 0.165\\nsamples = 11\\nvalue = [1, 10]'),\n",
       " Text(135.4247191011236, 88.33500000000001, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 10]'),\n",
       " Text(142.94831460674158, 88.33500000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(154.23370786516855, 101.925, 'X[1] <= 78.0\\ngini = 0.497\\nsamples = 13\\nvalue = [6, 7]'),\n",
       " Text(150.47191011235955, 88.33500000000001, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(157.99550561797753, 88.33500000000001, 'X[4] <= 123.5\\ngini = 0.42\\nsamples = 10\\nvalue = [3, 7]'),\n",
       " Text(154.23370786516855, 74.745, 'X[4] <= 119.5\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(150.47191011235955, 61.155, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(157.99550561797753, 61.155, 'X[1] <= 157.0\\ngini = 0.375\\nsamples = 4\\nvalue = [3, 1]'),\n",
       " Text(154.23370786516855, 47.565, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(161.75730337078653, 47.565, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(161.75730337078653, 74.745, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(150.47191011235955, 129.10500000000002, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(154.23370786516855, 142.695, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9]'),\n",
       " Text(222.7689606741573, 197.055, 'X[2] <= 27.85\\ngini = 0.478\\nsamples = 180\\nvalue = [71, 109]'),\n",
       " Text(169.2808988764045, 183.465, 'X[4] <= 145.5\\ngini = 0.375\\nsamples = 36\\nvalue = [27, 9]'),\n",
       " Text(161.75730337078653, 169.875, 'X[3] <= 59.5\\ngini = 0.1\\nsamples = 19\\nvalue = [18, 1]'),\n",
       " Text(157.99550561797753, 156.285, 'gini = 0.0\\nsamples = 16\\nvalue = [16, 0]'),\n",
       " Text(165.5191011235955, 156.285, 'X[2] <= 25.25\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(161.75730337078653, 142.695, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(169.2808988764045, 142.695, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(176.80449438202248, 169.875, 'X[0] <= 1.5\\ngini = 0.498\\nsamples = 17\\nvalue = [9, 8]'),\n",
       " Text(173.04269662921348, 156.285, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(180.56629213483149, 156.285, 'X[2] <= 23.1\\ngini = 0.49\\nsamples = 14\\nvalue = [6, 8]'),\n",
       " Text(176.80449438202248, 142.695, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(184.32808988764046, 142.695, 'X[2] <= 25.8\\ngini = 0.444\\nsamples = 12\\nvalue = [4, 8]'),\n",
       " Text(180.56629213483149, 129.10500000000002, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(188.08988764044946, 129.10500000000002, 'X[3] <= 34.0\\ngini = 0.444\\nsamples = 6\\nvalue = [4, 2]'),\n",
       " Text(184.32808988764046, 115.515, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(191.85168539325844, 115.515, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(276.25702247191015, 183.465, 'X[4] <= 158.5\\ngini = 0.424\\nsamples = 144\\nvalue = [44, 100]'),\n",
       " Text(234.64213483146068, 169.875, 'X[3] <= 30.5\\ngini = 0.487\\nsamples = 88\\nvalue = [37, 51]'),\n",
       " Text(212.5415730337079, 156.285, 'X[5] <= 23.0\\ngini = 0.49\\nsamples = 42\\nvalue = [24, 18]'),\n",
       " Text(208.7797752808989, 142.695, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(216.30337078651687, 142.695, 'X[5] <= 88.0\\ngini = 0.465\\nsamples = 38\\nvalue = [24, 14]'),\n",
       " Text(212.5415730337079, 129.10500000000002, 'X[5] <= 72.0\\ngini = 0.444\\nsamples = 36\\nvalue = [24, 12]'),\n",
       " Text(199.3752808988764, 115.515, 'X[2] <= 33.75\\ngini = 0.5\\nsamples = 20\\nvalue = [10, 10]'),\n",
       " Text(191.85168539325844, 101.925, 'X[2] <= 31.05\\ngini = 0.397\\nsamples = 11\\nvalue = [8, 3]'),\n",
       " Text(188.08988764044946, 88.33500000000001, 'X[5] <= 58.0\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(184.32808988764046, 74.745, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(191.85168539325844, 74.745, 'X[0] <= 4.5\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(188.08988764044946, 61.155, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(195.61348314606744, 61.155, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(195.61348314606744, 88.33500000000001, 'gini = 0.0\\nsamples = 5\\nvalue = [5, 0]'),\n",
       " Text(206.8988764044944, 101.925, 'X[6] <= 0.535\\ngini = 0.346\\nsamples = 9\\nvalue = [2, 7]'),\n",
       " Text(203.1370786516854, 88.33500000000001, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(210.6606741573034, 88.33500000000001, 'X[3] <= 28.5\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(206.8988764044944, 74.745, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(214.42247191011236, 74.745, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(225.70786516853934, 115.515, 'X[4] <= 157.5\\ngini = 0.219\\nsamples = 16\\nvalue = [14, 2]'),\n",
       " Text(221.94606741573034, 101.925, 'X[5] <= 85.5\\ngini = 0.124\\nsamples = 15\\nvalue = [14, 1]'),\n",
       " Text(218.18426966292137, 88.33500000000001, 'gini = 0.0\\nsamples = 13\\nvalue = [13, 0]'),\n",
       " Text(225.70786516853934, 88.33500000000001, 'X[2] <= 37.05\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(221.94606741573034, 74.745, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(229.46966292134832, 74.745, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(229.46966292134832, 101.925, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(220.06516853932587, 129.10500000000002, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(256.7426966292135, 156.285, 'X[2] <= 34.05\\ngini = 0.405\\nsamples = 46\\nvalue = [13, 33]'),\n",
       " Text(240.7550561797753, 142.695, 'X[5] <= 75.0\\ngini = 0.49\\nsamples = 21\\nvalue = [9, 12]'),\n",
       " Text(236.9932584269663, 129.10500000000002, 'gini = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(244.5168539325843, 129.10500000000002, 'X[4] <= 143.0\\ngini = 0.415\\nsamples = 17\\nvalue = [5, 12]'),\n",
       " Text(240.7550561797753, 115.515, 'X[3] <= 47.5\\ngini = 0.496\\nsamples = 11\\nvalue = [5, 6]'),\n",
       " Text(236.9932584269663, 101.925, 'X[5] <= 77.0\\ngini = 0.375\\nsamples = 8\\nvalue = [2, 6]'),\n",
       " Text(233.23146067415732, 88.33500000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(240.7550561797753, 88.33500000000001, 'X[1] <= 147.5\\ngini = 0.245\\nsamples = 7\\nvalue = [1, 6]'),\n",
       " Text(236.9932584269663, 74.745, 'gini = 0.0\\nsamples = 5\\nvalue = [0, 5]'),\n",
       " Text(244.5168539325843, 74.745, 'X[3] <= 40.0\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(240.7550561797753, 61.155, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(248.27865168539327, 61.155, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(244.5168539325843, 101.925, 'gini = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(248.27865168539327, 115.515, 'gini = 0.0\\nsamples = 6\\nvalue = [0, 6]'),\n",
       " Text(272.7303370786517, 142.695, 'X[6] <= 1.088\\ngini = 0.269\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(263.32584269662925, 129.10500000000002, 'X[1] <= 306.5\\ngini = 0.172\\nsamples = 21\\nvalue = [2, 19]'),\n",
       " Text(255.80224719101125, 115.515, 'X[2] <= 44.6\\ngini = 0.1\\nsamples = 19\\nvalue = [1, 18]'),\n",
       " Text(252.04044943820227, 101.925, 'gini = 0.0\\nsamples = 16\\nvalue = [0, 16]'),\n",
       " Text(259.56404494382025, 101.925, 'X[0] <= 6.0\\ngini = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(255.80224719101125, 88.33500000000001, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(263.32584269662925, 88.33500000000001, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(270.8494382022472, 115.515, 'X[4] <= 142.0\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(267.0876404494382, 101.925, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(274.6112359550562, 101.925, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(282.13483146067415, 129.10500000000002, 'X[1] <= 147.5\\ngini = 0.5\\nsamples = 4\\nvalue = [2, 2]'),\n",
       " Text(278.3730337078652, 115.515, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(285.89662921348315, 115.515, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(317.87191011235956, 169.875, 'X[6] <= 1.157\\ngini = 0.219\\nsamples = 56\\nvalue = [7, 49]'),\n",
       " Text(308.4674157303371, 156.285, 'X[6] <= 0.343\\ngini = 0.147\\nsamples = 50\\nvalue = [4, 46]'),\n",
       " Text(304.7056179775281, 142.695, 'X[3] <= 48.5\\ngini = 0.332\\nsamples = 19\\nvalue = [4, 15]'),\n",
       " Text(297.1820224719101, 129.10500000000002, 'X[4] <= 177.0\\ngini = 0.219\\nsamples = 16\\nvalue = [2, 14]'),\n",
       " Text(293.42022471910116, 115.515, 'gini = 0.0\\nsamples = 9\\nvalue = [0, 9]'),\n",
       " Text(300.9438202247191, 115.515, 'X[4] <= 179.5\\ngini = 0.408\\nsamples = 7\\nvalue = [2, 5]'),\n",
       " Text(297.1820224719101, 101.925, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(304.7056179775281, 101.925, 'X[4] <= 187.5\\ngini = 0.278\\nsamples = 6\\nvalue = [1, 5]'),\n",
       " Text(300.9438202247191, 88.33500000000001, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(308.4674157303371, 88.33500000000001, 'X[1] <= 65.0\\ngini = 0.5\\nsamples = 2\\nvalue = [1, 1]'),\n",
       " Text(304.7056179775281, 74.745, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(312.2292134831461, 74.745, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(312.2292134831461, 129.10500000000002, 'X[4] <= 184.5\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(308.4674157303371, 115.515, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(315.99101123595506, 115.515, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(312.2292134831461, 142.695, 'gini = 0.0\\nsamples = 31\\nvalue = [0, 31]'),\n",
       " Text(327.27640449438206, 156.285, 'X[4] <= 182.0\\ngini = 0.5\\nsamples = 6\\nvalue = [3, 3]'),\n",
       " Text(323.51460674157306, 142.695, 'X[2] <= 43.25\\ngini = 0.375\\nsamples = 4\\nvalue = [1, 3]'),\n",
       " Text(319.75280898876406, 129.10500000000002, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(327.27640449438206, 129.10500000000002, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(331.038202247191, 142.695, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABIt0lEQVR4nO2de3xcV3Xvv2v0mJEiK5It25Ij2RO/Y2LZIXYcJ45tAiThUWgSIJRCeJbLpeVSHi2F0tve8mhLC5THbXubAEkJbWmdNk0hJeEVY4nEYBucNMFxFFlSZFtybMmSY2ssW973j32OfDSa85jnOSPt7+czn8/MnFl7r732Puucs+fs3xGlFAaDwWAoDbGwHTAYDIbZhEm6BoPBUEJM0jUYDIYSYpKuwWAwlBCTdA0Gg6GEmKRrMBgMJcQkXYPBYCghJukaDAZDCTFJ12AwGEqISbqGQNTU1AyIiAryqqmpGQjbX4MhqohZBmwIgoiooGNFRFBKSZFdMhjKksqwHTCUF52dndTU1NDc3MzExASVlZUcPHiQRCIBwKZNm0L20GCINibpGjIiIgIsAq4AVtvf79+/nzVr1jA2NkZFRQWxmJ6hSiaTLFy40Gm/DTgAHAt8imwwzAJM0p3liEg1sBydWO0Ea79OoxPnAfv37e3tDA4OMn/+fCYmJli1ahXnz5+nv7+f0dFRVqxYYf/0M1Z5MRE5APzKUdYBoFspdb40rTQYooOZ050liEgjUxOqnWAXA71MTYi/Ap5RSg077HOa0xWR+Wn12nW3AN0u9Z7Ks7kGQ2QxSXcGISIxoI3pZ6yrgUu4mNicie45pdRZv7Krq6tPnDt3bm4QPxKJxODY2Fizj681wAqmn2GvBIaZmojt90fMVIWh3DFJtwxJS1jOpJWesJxJq6AJS0QanWfCbt/lUK7bgeMKoAZ4hukHji6l1Hg+9RoMpcIk3QgjIk1kTj6LgOeYmngOoC/NR8PxtviIyFxgFcGnSA4opU6G4qzB4IJJuiEjIhVAksx/ZFVy8azOeXZ3SCl1Lgx/o4iIxIFleP8ZmH52/LxS6kIoDhtmNSbplggRuYTMZ2nLgUEyTwmY263ywLrt7TIy/4HYgJ6qSL9aOKiUSoXhr2F2YJJuAbF28oVk/iNrAfAs08+4DiqlTofi8CxGROq5eBB09tdS4DAZ/shTSh0Px1vDTMIk3RwQkSr0zpl+9rQaOEfmf957lVIToThsCIzVt5eTeS79PNMPmgeAHtO3hqDMuKRbU1MzkEqlFvr9LuBtTfVMP2N1ng1N2wHN2dDMxHEVk+lAa1/FpB9sA13FFHLMGqLPjEu6QW/iT7uBfwv6Zv30qYEGLs77ORPss2bez2BjzdevZPrZ8QrgGFPHz0ngV0qp/Q77rMesoXyZkUm3o6ODRCJBS0sLExMT1NXVcfDgQeCiIEta0h0FRoDvMPVspd/8w23IlbQ7U+zXG9F/kK50/C7jmD1+/DhHjhwhkUiwadMmk3RnCDMy6Q4NDVFfX8/p06epr693+50ZwIZIYMbs7GJGCt40NjZy7733snTpUurr6xkbG0NESKVSrF69eooalsEQFiJyOfAyyDxmY7EYl156KfX19bS0tNg2bUqp58P025AfM+LJESISE5GbReRfATo6Oqirq0MpxcjICJdffjmtra0kEglGR0eddpusP0gMhqIjIm0icqeIfENEeoDHgFdC5jF72WWXMTQ0RFdXl7OYfSLSJSJ3ichbRKQlhKYY8qCsz3RFpA14J/Au4DhwN/CGtrY2RIS6ujqampro6elhfHyclStX8swzz1BbW2sXcR+QEpG7gW8qpYZCaYhhRmIlxJc5XpcCjwI/Bj6HvttFicib08fsyZMnWbRoEY2NjYyMjHD48GG72IXAS6zy3gh8VUSOWWX+GHhUKXWslO00ZEfZzela91G+FngPcC3wz8DdSqlfQHa336RSqRZgm1XWa4GH0In7UfMHmiFbRGQBsJ2LSXYBsJOLCfGpTOMqn1vGrD/r2h113gD0O+rcqZQ6kUezDAWmbJKuiKwA3g28HX1P5F3A/UqpMwUqvxF4K/BbQC3wNeAepdTRQpRvmHmIyDz0QdtOeK3ALi4mvCdKvWhCRCqBqxw+XY/WLbZ9+okRAQqXSCddS8LwNnQivAK4F/iaUuqZItYpwAb02e+bgJ+gE/z3zJMOZjci0gBs5WJCWwp0cjGh/SJqY8S6MtzARZ+vRd97bvu8y4jGl5ZIJl0RWYdOem8Bfo5Oev9Zas1UEalDJ973AEuAb6CT/qFS+mEIBxGZg75ctxPWKuBxLiasPeWm9mYpsl3DxTZtBP4b+BG6TZ2Funo0ZCYySddacvtmdIJrBr4OfEMp1RuqYxYiciV6euOtwC/Rc78PBHnqgqE8sFaWXc/FhHQl+qBvJ9mfzbT+tq4mN3OxzeuBX3CxzY+Z1ZeFJdSka13KX4tOtLehj7Z3A49EVUBERBLAr6N9bkffAXG3UurpMP0yZI/Vl86EcxX6gOpMOGOhORgCAQ48u81TOvIjlKQrIguBb6KfgFCNTrT/oJQaKLkzeSAiS9Fnv+9EP0rmz5RSnwvXK4Mb1pOPNzH90tpOKJ1GZnMq1hXoFmbQFEvYFCzpBrntxb7lRUTuAO4BbkH/mxqNOY4csf4x/lv05edd9vdGParwZDPOAETkD4A6dLI1fyLlSYY/Ey8Hfoq+Pe71Sql+CD72YfaN/4Il3SBKSbNt7bhRjyo82Ywza/oqBTyC/jPW3C5VYKzb5l4G/B3wRqXUj63vA59LzbbxX9AVaZ2dnVOUkmpra+nv76ehoYElS5YUsqqyobOzk8rKStra2qaoRw0NDU0qnhmyo7Ozk5qaGpqbm5mYmKCyspKDBw+SSCSm/M7a6+PheDk7sBZe7LBe03DrK2BSPW22UdCku3//ftasWUMqlaKiooLx8XHi8fisTbhwMSaHDh2ioqICW+rhiiuuCNmz8sWO6djY2GRMm5ubWbBgAY2NjWG7Z3CQ3lexWGxyqfNszQsFFbxpb2/nxIkTTExMMD4+zqpVq2htbWXv3r2U+bRtVlgCPNthekySySStra3s37+fXbt2hetomZIppnV1dXR3d3PunPlPJ0xEpMIe+zC9r5YsWUJzczMnT55k3759TrsZIb4VBDOnW0AsAZ63o+9mOANcGXROF/gS8HWl1BPF9LHcMeMselir3rYDb0DfTnkYuCqbOV3L5n7r1RnVW0YLQUGnF3p7e+nv75+8fOjv76e5uZmenh62bdtWyKoig7XC5/VopbNrgG8DdwB7gQvpMTlx4gTDw8OsXr2awcFB5s2bZxc1CnxXRAbRC0P+SSk1XPoWRZ9M42z16tX88pe/nLHjLGpY4/7l6ET7OuA59LzuZqVUt4ionTt3kkwmp/TVwMAATU1NjI2NMTg4yPLly+0ibwJuB74CLBSRf7fK2xm1pdX5EsotYwWpMGREZD060b4F2I9OlP/uXEKZ7S1jlmLUy61yb0Grnn0d+JFRPdPMtnEWJazVazehE+1r0fc43w/8m1Kqz/nbfG4Zs8StbrdeSeA/0An4RzNhYUYhpxdeCnwXWOm899G6T3KjUur2glQUIiIyF51k3wU0obUY7imGFoOjrncDc9H3NX9DKdVT6LrKCUsP4SDwWqXUXsf3W4BvAatn2yqyYmKtUHsVOtHeAuxDJ8B/L4UCn4gkuZiAVwP/adX//XJdnlyQpGtdahwE/lwp9bdp22qAQ8CXlVKfzbuyEpN29vkq9NnnN4AflmreSUSusur/DfQyVfusetYlFxF5FP1gxzdl2PYQeky/quSOzSCsVWivRSe6V6BXoO0A/iNMgXQRaUXLBbwBvQT/Icuv75WTSE+hku5q9KXGgkxPXxCRB6xt1+VdWYmwlvi+w3q9wMV51tCeLmFpBbwOnYA3ouePvw7sLfdVfUERkdPAnUqp+zNsezfwBaXUpaX3rLyx9KRfh06029C6wDuAB6P4RBURaQZuRfu7Eb0AZgfwUNRXGUZGZSwKiEgt+kj6LmAt8I/oS/pfhulXJkRkMXAn2tcX0cn3W0qpF0J1zFA2iEgT+m6DN6CFf36InqP9jlJqJETXssJqx+vR7bgeLZy1Ay0HG7l2zPqka01/rEOf0b4JfSn1dXSHRV7Gz7q/cRs6+f4a8AO0/4/MtH99DfnjOEN8A3A18DA60T6klHoxTN8KgXXG/mvoM+CXMfWMPRKPLTJJVyQFnEU/KPBeW7CjHBGRS9G3q70LLfDyHqXU18L1yhA21lXR36MfQ7UW/Yf3DuDhmfy/gDU3/Rp0An4lsBv4Ffp++P2hOaaUCvxKJBIDgHJ7JRKJgVzsvGwL6V+mutB6ofX51h21F/rMvSWf2ITxynes5DpGy+mVbV+ip6FOoxNQPGz/w3gBl6CT7yjw7UKOuWxfWZ3piojau3fvNPGKmpoalFJce+21qAwrgUREdXR0TBF+qa6upqenZ/I3brbZYK9WShfeicVi9Pf3IyJcc801s3LFklcfpFIpamtr2bhxY+ixcfPzwIEDkwIpXj7a9iJCMpmcHKfj4/r2zmQyWfZ9nylGAN3d3VNEZMLuy3JBRNTjjz8+GUt7vPT09LBo0SJWrFhR0FhmnXTPnz/P6dOnqa+vz7TdNekODQ1RX1+ftW022El3eHi46HWVG0H6wPpd6Ek3n7HiZx92+wpBufRlueCX16zfFCyWWS8Dvu+++1i6dCn19fWMjY0Ri8WoqKigqanJ066xsZF77713iu34+DhKKdauXZtzAzLx4IMPTqlHRDh79iwrVqygpaWloHWVE5n6IBaLoZSiubk5MqpPmfysra2lvb09kH16/9ttXLx4cZE9Lx1ufTk2NsZVV13lmjwMmUnPayJCKpVi9erVLFwYaGFdYLJW9qmrq0MpxcjICJdffjmXXXYZSinfHbajo2Oa7bJly0gkEgWV48tUT2trK5deeimHDhV84VhZYC2rzBibyy67jEQiweHDh52/D/XsKJOf8+bN47HHHgukIpapjXV1dTQ3z5yVwZlitHDhQiorK6mpqQnbvbJj2bJlHDt2jJGRkUnluuXLl9Pf319w5bqspxe8fu81veBXTyGnFwL8bsZfdlmJ8wbgw8B1wPygsUH/y/sF9Jr6kt52lu9YyXWMlgPW7YHvAL5mxnnhKLVyXVZnulVVVUMigtsrkUgMZrJLJBKDXnZetoX0r5B1RRURqRKR3wT2oB9R8z0gGaQPHLH5c+B3gOdE5CPWrWglId+xkusYjToiciWwE3hfVVXVSJC+jMfjF0Tky6Xsv3KkqqrqZElzRg63XswDRtBP8f0i8KfW940Bb9s4hX5Q4KfRSzYD2Wbh31z0st0r7HKtevvR0osFqytKL6AR+JjVzh+i187H/Gx8Pm9Ai8gMWX19eYnb9JTVZ29GK0wFHivoRS43om+U/1mhx1kJY3AJ+h7yF4D3AxVB+9HaV+9Ga9W+GevK1rymxErQ9y1/OkP83m6NwYLeZpeLk3egV2thDerdWdi+Bvix9f4a9JNZPRNDDv59AfjbDN+/G/jJTBt4wHK0BukQcC+wvgh1tAF/ARwH/hWtmVrsdrVZ9VVYB+lTwLyAtnPR92PGrZODUaAt7L7KIQavB3qtA19zHuVcDzyB1idYEXa7ovQC3otWTqvOsE2AfwM+V9A6c3Dy68DvWO/j1oAOujN8GfgD6/0c9I3H1xYwgL9ulTltgFo7bwq9GiX0zs6znYJ+DPYD1hnQZ4BFJai3DvgAWrD6cfSy6coi1fVu4J8dnxVaxS6I7ZvQ+gFO27vC7rcs2r4ErSH7DPDyApVZBXzUOpD9MZAIu51hv9Bn/+PAGo/fzEcvLPmLgtWbpZNzgAtofVz7u+eBfwhgGwcmgFc6vltbyDNP9JTCn3hsfytwW9idnUf7qtAau3vQUpr/E7gkBD8q0Ov3d1lnYh8GLi1wHcPOJAusAGoC2g4C/8/xOUkZrDoEFgJ/aCXGT1KE1WPoK4h/s8ZP0Q6a5fBCr9T7xwC/+wuvvJJ1vVk6mbDOcBKO7z4F/F4A2wrLdk7YwS63F3q+9vetA9yP0POUBZ2WycO3jWg1thPoqZ1kgcr9DnBNjrb3A9vDjk0Ofp8EBoBlJajrtdYVwN+F3e7Z9pr1gjdRR0T2AyvRc6lfVEr9ImSXMiL6oZwfAP4H+s+famUeMZQVohXAhlWJ1O1EZAFwSs1g0ZtIEkamz1VgIqjQRz72xRZEydYH4HeBV4V9dA76Apaiz3gnp43CFLEJUwCnXESGytXfQrQnaFsKWVYoZ7q53owcdPFDPvbFvqE8Cj6UmjAXPIS5WKLcFuuUm79+FHJfK2RZntoLXk/0jMfjnD3rfhXkt72zs3OaktTJkyc5duwY1dXVnk53dnZOUZGqrq4mlUqhlCKZTPraNjY20tDQMEUpLZFIUKoDUGdnJzU1NdPU2hobGxkbm5lXeul9VllZSV9fH83NzZOPTRcR1w7Yu3fvpGpcXV0dBw8eBOC2227L2rarq4t4PB5YyyEf0se5Xf/Y2Bhbt24tev3Zkq7QB3DkyBHOnj1LPB6fVDArFzLlmYGBAVKpFLFYdioIbvtttrnDM+mmUqmFboVZWd3V1mu7iLB//37WrFnDoUOHqKiooLa2lnPnzrF48WJfHYd0W1ucIohwzpo1a3jggQdoaWmhpaWFsbExEokEDQ0NLFiwwNe+ENj+j42NUVFRQSwWQ0SYP3/+jBXkseM+Ojo6GfdYLEZPTw+9vb2+Y+mJJ57ghRdeoKWlhcOHD08KLR05ciQn21Id3Ox2Dw8PT6k/Ho+XpP5ssf2142X3E8DKlStD9i570uNviyeJCKtWrcqprGPHjk3JHdkeiHxVxjo6OhgcHGT+/PkArFq1ivPnz3tuGxrSz7G7//77p20bGBgAoL29fdJ2YmKCyy+/nPPnz9Pd3e2rBpVua5f9/PPP8+yzz3oG4amnnqK+vp7a2lpGRkYmbU+cOFFQ4Z1c/O/u7vZVaytX3OJ+/PhxwH0s9fX1AWS0HRwc9LS1t7vVe+FC8f/n82r3hQsXsj7bKjZu/nZ1dVFXVxe2e1nj1p6BgYGsD3xuZe3Zs4cNGzYELsdzTldEVE9PD/39/dTV1dHU1ERPTw8VFRVs3ryZRx99lGQyOWV7X18fiUSCl770paTbnjlzhkQiweLFi31Px2finK6IXAK8aOZ0p22fNlZGR0epq6ujr6+PLVu2eF41pdt2d3dTVVVFW1sbra2tQa7IzJwu5eevH2U5p5tIJAaTyaTrnO727dtdbePxuOf8am9v77Rk3traSn9/P9dff72r3c6dO6cl+lOnTjEyMkJDQwMnT56ktbU1K/vR0VFefPFFFi1a5GqXLyJyC/A3ML3tZ86cmZxrsn0XkTcB/xr4KBNx0ttsJ9Xjx4/T2trqOxefbt/X10djYyNtbW1Z23Z1dQGwfPnyArUueN0DAwM0NTUxMjLCvHnzuOyyy4ruQzZk2j8OHTrEsmXL6OrqYunSpWG7mBWZ2tPT00NNTQ2nTmX3pPZMZdlP68gqd5TTrRzleMsY0Az8M3rp7E0BfTiBFtr4LrAkjD6KQn8HtTe3jOU9RmPAZxKJxPmA/o6GPaZKMe6KVVaoQUGr+Oyw3t8NfDAL29uA71nv/xr4wyxsbwI6rPefBv6sCG2LocU0jgF/BtRmaV/NxSWhH2EGLNdEC6/80nr/ceArWdiuA7qs9x8AvpGF7TLgKFqz4h3Av5S43Vegl0uLNSbuC7svHL7VoBfedGJpLvv8finwNPAlMiieRfEFbAH2We8/AXwpj7I+gKXfAvwL8I5sywh7Fv9m4GHr/SPoZBiUP0N3fi62N1s2udj6IiIvQSuavRN4hVLq40qpM9mUoZQaV0p9BtgMvBr4uYhsLKSfIfCX6DX/oPs92z6zx8rDwE0igZ9wcTPwiNJ7yk7gVms1VqlIr/9NIlKaf209sFbAPYoWfXm5UuoFPxulVDdaFH8N8KCIzCmqk4XhL4FnrfcPo/sjVz6JViXLuazQkq6IVKKfRW/vSD8AbhCR2oBFpICfWu93Ai8VkbkB6hXgVWhxb4DHgGUikvfkmojUiMin0QP5H4EtSqkn8ilTKfUs8Ar0Kq//FJEvlclAz8Q4Ot4AvwQaRCTofTuv5uJYedYq66UBbV/jsO1HX32U8q94p++9aJ2KS0pY/zRE5ENoucfvAm9VSqWC2iqlTqLb1A/8SkRuK4qThWOci7niF8BcsR5hlQNjaA0Z0CdsrxSRqqxKCPGU/73ouRBxfKfIUc3HsvW9XEUfpRVQl2b7rTzb8xWgG9hBkWQWgSbgG2gFrq+G1XcFbM848N0Av1tg9dEKx3ejQGcA21rLNifxnAK08VKr/rVhxzvNr+/hkL/MsQwB9gJ3h92eLP0+l2/bHe1XwPuyscv6acAF5F7gSWV5b7ERrSGaC+vRKlx+PA5sU0q96PjuSvTcaT68DfgbpdQn8izHFaXUceCdIjJMac/UisWVgO+0i1LqmIhsV/qs36YdPej9bM9Ytj/Lw8+cUUqNWPU/GUb9biilbilAGQq4ugDulJor0Rq5eaGUUiJyHRenGwJhVMYMBoOhhIT9R5ovNTU1AyKi/F41NTUDpa630HXmSlgxKhd/svGrmD4Vu/6Z3r5S1+9XXq5tKdmZbj7iOV4+JpNJent7XbcnEokLqVQq48Eln3ohOitzoraSyM8fvz7z6pd8hZaK3ade47zY9Rdy1dRMrN9v3IFeEDY2NtbsV16AvDNZTjolm9NNpVIL77nnHpYuXUp9fT1jY2OMj4+zdevWSXGce++9d9r2bdu2TVMKstV9RGRSLCWTrVV2rFD12iuojh49GlmFKKe/iUSCkydPhuJvpj4bHR1lcHAwSJ+RS58F7VOnipatWJZKpSbVzvLBb5x7jeVC9FEmVa0DBw4UrPxs66+srGR8fJyenp6i152p/lgsRldXF4lEwnfcAYjIlAOmU6EuFovR398PEGQMux54S/pH2rJlyxgcHJw82q9atYrDhw8DWrSkrq4OpdQUMQnIrBSUSCSmCO9ksj1w4EBB6z18+DBi3Rp69OjREkUtOOnqa7aa1urVq0vuS6Y+c+74bnHfu3cvkFufPfnkk57b4WKMUqnUZIwqKyt9lxJng5fvmfookUgUTMErU9xramp8z7ALhVu/AyUZh265IpXSd8S5jY3du3dzzTXXTCvPqVBnt6WhocGzLHsculGy6QWvU3X77MRt265duzKqSB0/fpz169d7Dii/snOpt6urixtuuIGKiopITS+4qW2V2l8RUW6xGxgYYMOGDUXpsyC2XmNp7dq1ecfIb5y71d/T08M111xDdXV1XtMLXu1rb28nFosV9fLerf7u7m62bNkSWv19fX1cd911WU3viIjasWPHtLJOnDjBunXrgozDzML6pUq61dXVJ86dO5dx8UJVVRXnzp1ztc1nnqa6uvrC+Pi4mdOlfOZ0vcaDX5/lM5Yg/xh5jfNi1x/1OdWw629ubp6U+3Qj6JyuX1lec7ph3qDcmOl9+ueqqqohshQNCVp2+jbnd1F4nlrQVyKRGMw2RkX2J2uhl0L0mZ9tkDgVQfAoq7GcT/1hj9lyq99vXFVVVZ0oVFlTxkSxAlDoF/r2tmPAWuCPgC8EbWQB6n4S2AR8EPjHUtSZhW+1wI+Bu3A8lj1tELzGit1VIfj331bsfhfHqr8w44dehPPf1vufo/UxSuYTcAN6OWojekXXlkLXj14EdCPwW8B/lKJ96MUqDwN/nN7PwH2UYOUaWpDnBNBs12/Fu9f+Lsvy6oBT6GXbXwM+km8sI3+froP1wJDSK3sewSE0oZQaLlalojUZFgF7gH9Hr7WOFbPOoIhIwvKpH70UcfJRCE7/lFLfRT8a/SER8X+mUeH8awVaSItdun8h4BQ8esj6XEqfbgYetuqbFE0pVP2iNUjWoJXDHgC2i0h1Cdr3fnSS+6z9haPO30GLFOUjNhOEz6JVxAbs+pVSu9AHt7fnUN7LgJ8rpU4D/0kh+qrYR54CHsE+bgUTtOyhAm4uQb3vBL7t+KyA341APOajE8a3CSj7CNwBHEEvgy6Fj98FTjs+HwCujkDsdtljB/htrBWtJaxfAX9gvd8O/KzA5b8Jh7aAVd+fFrlN70afEa7y+M3LgRHguiL58EfoZeWXZNi2EjiPdVWRRZlfBT5mvb/UamNWMq3TyizFICtAMAUYBN7s+O59OERrilh3F/B7js9vA1oiEJMnrAFQlaXdX5UqyaAv41/u+Hw/lgZyiHG7Ei20U2N9rgZ+p8Q+/M+0+s8CGwtY/lPApxyf76DIYvjAPcCjAX7XBXy8SD58BA/RK+C/gBuzKC9h7WPXpvn/x/n4WRbaC9Yl6TB6YB70+32B6z4K3KmU+n4p6/VDRFqAUaUve7KxE2CpUuq54njmWfefAK9WSk2/IbJ0PrwGPbcYmccui0gf8FGl1L8UsLwPK6V2FKK82YqINKBFtNqUlrNERB4GepRS/yPncssh6RoMBsNMoZz+SAsspFIMYY1SinkUS2gj23qC1hVVgRs/ih3nsONSyDEblbLCsi0kZXWmG+Tma8dvUQW8CbuUN3771VWqeoLWFbRfCt0n+VLsOIcdl0KO2aiUFZZtIQlTxNwVP6UmN1GN8fFxXnzxRa666qqS1OsUwNi0aVNOdQatyylcUuh6nAIwdptqampob2/Puqyamhqam5uZmJigtraWoaEhjh49yp133gnogZ/J1nMFTx5k26cAR44c8Vz1lg2Z+vHgwYMopbjzzjsnV+ZlikuQmARpn7NPbIGdRCJBkANCelmNjY00NDRMxsp+BHm2pJdl+9Xc3MzJkyd9bTO1qbm5meFh7zu53Gxramq49dZbgcx94bcSEoKP4Ugm3VQqtVCp6Qo+mzdvBqaLhtTW1jI8PMzKlStZsSLXRx+512srVGUS06itrWVsbMy3s7Ol2MIo6fXYAjB2Ur/iiityLmtsbGzSZ6UU69evp7e311U5DKarOxUKP9WvTHGurKykubkw+T/TmInH41RUVOSlVOVsX5Axe+zYsSkCOIlEgra2tqzaYsdqeHh4cr8DWLFiBXPn+j6eMGNcWlpapgjTrFrl/8i89HFmj9mGhgZf+0xjtK6ujqamJo4cOZKzuh0EH8ORnF4QF+GK5ubmwEfnXC4T3Oo9f/48ra2tvnWb6QXvcjKJhwwMDHD11VcX9RI71z4t9vSCeAjgDA0N0d7eHij2pRizs2F6was/WltbXbedOnWK1atXB29/VJNuJr/so42bmtbx48c5f/58zjuxV6d4dcjAwADr1q2jqqqqYMkwU4Lq6+tjw4YNeSlRpdfjpaS2devWQKpQdtzc+qW7u5utW7cWNcH5+eZWp1v7jx49ysaNG/NOugVQW8v5gOfVvpMnT7JmzZrAql9ebclWwcyrrBMnTtDe3u6ZOL2UxLz2Dy/bwcFBrr76atf+sHOPT7sCtT+S0wtVVVVD4vI49Z07d5JMJhGRycuC4eFhRkZGaGhoYHR0dFK7tJD1AkxMTLBhwwb6+/upq6vj/PnzHDlyhAULFtDZ2ZlTnW6k1zM0NERjYyM/+1lhn6/Y1tY2JZYHDx5k+fLlgJ7bDEqmfjl+/DiLFy9GKcX8+fM956MtMZqCk0uf9vT0TF4650t6fPv7+2lqauLFF1+c3OZGPB5/wa/8XNrX1dXFwoUL+elPf+pmFqgt3d3dNDY2cvLkyaz/a8jkV19fH4lEwnf/dfPjwoULVFV5Pw3drd7GxkbPMRqPx33bGHgMB1lBEfaLLJS/yKAAlG+9Vt0lU6jya2ep6glaV6FVxUoxloL0aTweH8yjnopEIjFW6rgUa8wWUkEsn7JKaevXF7n2VUkGehF2nH8C/nfad29CPwo5VuS61wLPWe8/DXy2CHVcD/RhLRW1vksAPcANRajv08CfW+8PAuvzKOs76GWnl6KXUNYUwsci9+kXgU+gl5sfAZbnWV4Mrfr2YzzW6QO3AwPAlUVu3zLgqNW+T2BpmORQzndJ0x0B3gP8BGuqModx91nrfRewLgvbjwNftt7/giw0FdDiO1+33u8CbinleCurxREAInIjsBX4fNqmf0WvqX9PkV24Ga0MBfBD4G0iUlGowkWkCp0E/lApNWZ/r5RKAX8IfFFE4gWsL4bWk/iB9dWk6lUOZcXRffMDpdQI+iBR7P4oBLcAjyi9Fz4C3JRrQaKvQb+MVvn6NaXUGbffKqXuBz4EPCIixXyWzYeB3Vb7cupfEXk9sAr4m7RN30Ari705B7+c+1K2ft3ERaW4x9BxzKZe2/Zh8ujvnChlhi/EC30Z8C8u295LkcVcgO8Dr7fet1r+XFrA8j9vlTntjB19BqXI8UzFpb45VplLrM+/Bvwox7JuRO/c9udfAN8Pe8z4+LwYeMGON/AWLP3ZHMoS9BnbnmzGBPAOtPrW24rUxueAf3KMoWNkKYBjjZH/67Ltj7Pd74Amq83V1ufXAT8MaGtr3NZZnz8NDAe0rQZGgXnW52uAp0o65kpZWYEG0A12R2XYJmShIpRD3cudCapIdSwE2j22X0kRVc7Q2sEKWJ2DbR+wL+wxkqXPD6N1mu3PL7HavzCHshJWAnftPw/bHwJfLFGbT2R7MERLUFa4bIsBL8uyvG8zVfbTPoFZGcD274BzObb9M84DBFBl1fvqUsReKRXNuxe8UFqQ2G2bAn5UxOp7gf+DTi5FQSk1iJaxdNv+38Wq2+Iouo25qJB9AvhVYd0pOp8DahyfnwY+hU6eWaH0FND8XJxQSr08F7scuRM9FRcYpdSjHtsuoOevs+ErgFNV7TB63B0KYHs3ei42F74FdNsflFLnROQP0E/aKAmRvE/XYDAYZiqR+yMtX2WmclDoKkfbUsUmqpRL7PIZ/2HZ5kNY9eZD5M50JcAyP+t3qByX+mWyS8dPSATAz89cfQzL1u/R6E5BD7/45OpjMfHz2U/UpBRtyqd//ez9+he821iser3iHkRoxsvnRCKRc9nFEmGK5JxuuvIVTFUz8lP0Srevq6vj4MHsHjjhJSRiC2C4qWoNDQ1l7aPdRhEhHve+IyyTctXAwACpVMq3XV6qU9kIsPgJrXjVExZB+tSvTel9duTIERoaGnyVsbLBS0UrSD27d++eooT34osvcvLkySD9m1F17vDhw74HHIB9+/blOq484+5n61YvwNmzZ3MWsZEiiTBFMunaCkQvvPDCpAJRY2MjY2NjgVS20u0PHz6MiGQtv9jR0UFdXR1KKUZGRibXae/atWtKPbaC0+HDh4nFYlRXV/uWnUndq6amhhUrVtDY2BjI1qmydvLkSVauXElLi/dTaDIpNCUSiUlVMbc279u3L3B8MsXGVrcaHx9n2bJlvvEpFm4+P/nkk4Hb5ByXIhJIGSsbMsUukUgwMDDA6tX+t/M+/fTTU1TNYrGLs4hu7duzZ49rG2trawPJfK5bt4677rqLl7zkJdTX1085ecgn7m7b9u7dC+gxnT7OUqnUpOJgLvUeOHAgSFflRCSnF7yENc6cOcPmzZtzEsQ4ceIE69atC3QJGGSawq2e559/nquuusrWLM3Kx1QqxbJly3Jq3/Hjx1m7di0VFRU52a5fvz7w5aVXfLxi4+djMQk49eS6za1N3d3dXHPNNa79na2PuQq62PaZxJKC9m+uQktefgdUc8t6m73da19avnx5XmUXY4xGMulGYU5XRNSjjz5KMpmcFMewxTWWL1/OokWLZtycrojQ09Mzpb19fX1UVlayaNEie+eZTLqZ4tPT08OWLVsiOafr5rMttPLSl750Wvt7enqoqKhg8+bNZT+nKyK4tT8Wi3HttdcWZU7Xq14RYfPmzRnHnd0n+fqcqWyvehsbG5kzZ86U8V5IIjm90NvbOyUQp06dYnBwkObmZo4dO8bSpUuzsrc7cMGCBYF9SCQSg9u3b/ec07GVtZx1DQ0NkUqlWLRokWf5mWxt9ac5c+Zk1b7R0VFEhBMnTnD99ddnXa99IGlpaSGZTLraOlWU/OLjFpuqqioGB4siKOaLn8/xeNyz/ZnGZU1NzeQlbaHIFLuenh5aW1snn1TiRbqfXV1dk6Ll27dvz8rWHltB+szN1q9er7jH4/GsfbYTcmtrq2/ZQcd7Qcm0YiLMVy6KVdnYR0GhqxxtSxWbqL7KJXb5jP+wbIsZryiOs9AdcHVM30M8AFxO2lrrgPbPAe3otdYjQFOR/Pxz4FPW+/uA92Zh+0mspZ/opY0fzsL2d4G7rPd/RZrqmo/tu7m4Fv9PgM8VIS6fB/4u7TsBfgq8PezxlUN74taYenna98vQy2qzXjbsU99ctEZAHL30+xABlbyAS6z9ZQ6QRGstBFLfQy+LPQksQK+uOwlUBbSNoVdTJq26TwGXlKh/ngCuBSqA40Br2GPG7RW5xREO2oFRpdQhpdSL6CPX54IYishy9NLOJ5VS42jpuYIvsxQRAT4GPGN99QjZKSV9Cq3EBdmrLOWj0OS0PQD8nmi1sYIgIncA70Mn9EmU3js+CnxFRAr7sLfi8yDwvFLqh84vlVLPoZez/jCjVe58Ca0vcBZ4Cp0Mlwe0/azl2ymlVA8wDKwLaHstWrr0mFLqBbSexCcD2q4DTiqlepRSp4C9wLaAtjkjIovQ2g0/V0pNACn0SUwkiXLS/W2gw/H5M2iFryD8DtBp7eSg14W/t4C+AZNJ5J/QGrJgJV0RaQhYxDfRwh+gNSNuEBHve77Avn9wGxd39A7gKhHxvRdLRC4FXsXFWD4EfFvp9fOF4nrgaaVUptVAjwFjwNUFrK8UrAR2uGy7F1hS4PoeQh+U7XHWiR7XQfgRVuK12JWF7fvRJyk2nyO4zsFvp/32J+iDb7F5P/C4lXBBazg8UIJ6cyPsU22Py4UR4O9ztB0Adjg+vwWHslARfbalF1+Xg61Ytu8K8Nu3Wr8Vx3cK+L0Atq+yflsZdh+bV1bj45+BYzna/g36qjHIb1PkKMyPng75O8fn3wUulCA2PcDDYfdR0FfkbhmzkaD3jgW0zae8fOsuhm36b/OxNZQHpRhb5bjfWdN8lMuYjmzSNRgMhplIlOd0gfxVx0rpRxRVmLyY6Wpn2RJVha58YplPHKM4Zv0oB58jcabrp/7U0dExTeDlwIEDiAh33nmnnzLWhVQq5XpwCaokJCKqo6Mjo+AJwG233eb7yPLHH398sg1O2zvuuMO1DX5KSAGUkjzb79WmTZs2ea5uS++XyspKxsfHGRjQ49paLeRq29jYSENDw7Q+dYiRlHzF2p49e6bEYmhoiJGREeLxuGt7bFtn/1ZXV9PT00MqlSKRSPjaZoplX5/WyvcaH5B5/zh48CBKKW666aa8FLw6OjoQEZLJJBMTEyQSCbq7u3nDG97guVCjUPtdOkHU//bu3esqFuTVD6UiEknXnvZxUxkaGhqivr6e06dPU19fn26Lm62987qpDDnsAy0LzteP8+fPZ20bRGUp1/aLiGdsveLjF49i2RYTEVFufeTnU762fmMr1z70s/UbO25ll2q/yxSrXPezfOotJJFZBuylMtTY2DgtyCLia2srCS1btozBwUH7n05WrVrF4cOHGRoayspHNz9s9TI3P5544gkA7rvvvqxtvbbt37/fc7utlOTWfoAHH3xwmk+pVIrVq1ezcKG3sl26bW1t7aQSnJ9SWrptLBZDKcUVV1yRcWcpFZn6CJhUYcvWtrKyksWLF/vaZorluXPnaGpqAjIrZdn9m6kPGxoaJpe9e6nGuY2dxx57LGPZsViMiooKT1u/cXfq1KnA/ZEJv3oz9UNDQ0Oo48pJpM50Xba5qgj19/cHFenw2x7oTNfNj6NHj7Jx40bfejIpOA0NDdHe3u5qG9D/nLZ7xfa5555j06ZNOSmlHT9+nPb2djuRZmXb19fHxo0bqaqqCuVM102hy6s9tq1bmwYGBtiwYUNOtt3d3WzdujXrPkylUhw+fJjrr78+r7FVDOUwx/acz3Rz8dmxn5rpherq6hPnzp2b67bdy0c/Vfrq6uoL4+PjBZnT9fKjubnZVxTEzd7LNt85Xb/2+/W/1xRBGLbFJMgO7ZU4i2XrN7a8bKurqzl37lzGbVVVVa7b/Mou1X6XTr5PdInC9ELoNwpnegGN9vuqqqrTZCmA47R3vvfb5vXKVogkvZ6qqqoThfA/3+1psR3Kpk3Ol197vGyjKoiTTR+V0tZrfPj1YXq92ewb2bapGPtdkFc+8QjjFWrlAYL5duB5YLlHZ34IvSJlSYl8uhwt6hFDr+/+RNCBBCzEEhABvgB8Jqhtkdv0MeCrQCNwBC3iEsgn9NLPeyzbZ4H1Wdi+HWvlIFqwZEtE4rETeDWwFTiYjU/oJeFvQi9zPoJeaRjU9p+BdwFXAEPo/1yC2t4NfBC9HHkUrZmQdxyBS9HCNbXAnwJ/HYU+8vFZ0I90XwG8E/hulHwO3QGPwL3ZGrSrA/z2g0AXcFkJ/Hof8E3r/WuAnxNc/ek3gX+33m8D9kQgzgI8Dvya9fke4P1Z2P8H8BvW+68CH8vC9lvAb1nvPwd8JQLxaAZOo5W6bNWsywPaxtHL1+dace21DyQBbKeoY6FFbl6dRR/22fuK1Z93FCgevw48Yr2/GvhV2H0UwOcrgW4rLnOtg0ZD2H7Zr0gujhCRrwB/DdyklPJ9WJFS6kvA3wOdIvKKIrvnVOh6FtiAPsvL1vYxYIWIzC+se1lTD2xCH7QgC8UyEakGtnNRPOdh4KaAtjHglWiRINCXf0FFWYrJbwO1SqnTSosAPULANqGFfn6llBpSeu+fS5rSmgdXAwNKKfvm1/lo4ZYgXIGOn612tzALWz+cY/YXQJOI+N+OES43o7UYlFJqCC0N+66QfbpI2Fnf5UilgPfkYHcQ2FlEvy6zfFvq+K4toG2DZXu147vDWLq2Ice7zfE+afm5OIDd/wFOOz7Ps2xfEsD2g8BZx2chAhqo6Ev6FsfnP3e20cf2WRzCK+hL8/qAtr8EHnN8nkPAszO0stcTjs+1wLwCxKLG6s8bHd89BzwUdj/5+D2O44rL2m8D6QmX4hWZ+3SdqBz/XVRKFVuj9RTwPfSlnF3n8wFtx9BnTU86vvsS+lI2VNLa8Dy6jUFupvwl8LeOz0PAf6L1W/14GviawwcF+D+Lpsgopc4DRx1ffRN9IArCQ1w8c0cpNZJF1d9Dn0nattnczPoIeirOtj0DnMnC3o1x9FXMY47v/ho9jRJlvoPWOAZAKXU4RF+mEYlbxgwGg2G2UNI53VIKnRRb+CKqoi1eRNXnsERKoioWE5btTCSK8SjpmW4pb4rP52b1QpRfiDoKTVR9LnZfhVFvVBdaRG1MFpsoxqPkc7qdnZ3TFJF6enoAvUKmkOzevTtjPdXV1YHs/Va/dHZ2UlNTM6loVFtbS1dXF2fPnuXOO+8EdKen2wVRd8p1xY4f6fEHrSqWr8/5qp3t27dvmjJUIpEI3rAcyTQebbWzeDyeMRYQrA+d46+uro4nnniCRCLBHXfcAWSOs83evXunqJ2dOXOGwcFBfuM3fsPX9umnn55Ub0tX2fLCa7yHOWa9CLJCzRkPWyXt7Nmzk+I7pabkSXfNmjU88MADDA8P09LSMk34pZA8/fTT0+o5d+5cIAESgFQqtdDtKCki7N+/nzVr1jA2NkZFRcUUoZHe3l68bAOccXqrzeSI7fOhQ4eoqKggFtN5cMmSJXn5HGB7zC+Wx44dm+yrmpoaqqqquOqqq7JoXfZkGo+JRIJNmzZx9uzZvOLhHH+HDx+mpqaGiooKzzjbtk888QQvvPDClLG7detWjhw54mu7e/duWlpaprRnZGSElSu9/2f2G+9hjVkvvHyGzPGwYxkWJU+6Tz31FPX19dTW1k5RCNqzZw8bNmwoaF2Z6unv76e5OfjBuKOjI6N4BkB7e/vktomJicltzz//vK+t27ZTp06xevXqgsUgHTefjx8/nrPPfu21VaXuv//+adtsTYEVK1YwODjIyMjIlO2PP/540WIB3uMx13gcPXrUs01etraGbiZbWxnOL85u9QZR1culvUNDQ6xduzbb0BcMN79OnDgBZM4DTz75ZGg+lzzpbtmyJeP3l112WcHruv322/Oup62tDRGhrq6OpqYmuru7Jy97/dqSbmsLYgNMTEywYcMG+vv7qaurm9zhGhsbJ3euYpCtz87B7OWzV3vb2toAptl2d3dPTimVclw4yTYeBw4cIB7Xd0y5xcO+enArO1O5zz77LMuWLePChQu+tpnqHR0dnRxbXrZ+5DJmE4lEUcdstj53d3cTj8cnpUkLkQcKScmT7s6dO0kmk5Md50xkixYtKmhdvb29U+qxz3LtuV0/EonEYDKZdL1kcmvL/PnzaWtrI5lMZrSLx+Ns377dt+5ATmZJJp9PnDjB/PnzaWlpydnneDzuagt6TjeZTLrO6ab3VXd3N83NzdTW1gZtWk54jUevNgXpw/Q22Qcor7HhZjs6OoqI0NbWlnW9o6OjjI6O0tra6mnnNd7DHLN+dXrto+Aeyzlz5pTKzamUciVGKdWl/OrKt56oKmWVo8/F7qtc643H44NhtCks25n4imI8QgkE8AqsJY/AJ7CUiwpcxzuBDhxiNOj7kvcAby5gPX/IReWlSfGXKL+AO4DvWO8/D/zvsH2yfPkecBsXxV8CLbEuQL33Yon8AL8CNhSo3Lloxa+4NeY7s7CtRa8KrAc241jmG8C2Cq1mtwCH+EvY/RviuNoG/Nx6//vAV8P0JyzBG6eIxm7gfSJSsKWFInI58BfAR5QVaQClBUw+CnxBRAo1l+FsS2CxmJBx+rwX+H3RAjShISLL0QI4O5VSE8APCC40k0+9YtVjL9/tBb5coOJfDnQopc6iTwDWikhDQNttwD6l1Chaya41izF7LfCcUuoYWq2sBXhjVp7PLCK1j5Z8R7N27lczdac/jD7dLxQfBeYqpXanb1BKPYoehP8r30pEZAFwFVp/FXSbbhGRSGpaAFi+3cLF+HdS+PjnQjVwAK3fANq/15Wg3s3AmFLKVln7L3Q8CsGvY8VZKZUCfmp9F4RbsdTblNaD+BH6KiAItzlsFVrq8UJA2xmFlW9ew8Xx/gRQLyJXhuZUCKf669E7eNEEhdGKVa6XU17bsqzn81jj2vocs9r2pjAvX3x8vtXysTJsX3z8fHkp/EQrdJ0qQrli+f8Wx3f7gBcC2ivgQ47PPyK42pkCPht2H0bhxUXZy/mO78axptfCeJVc8Ma6nFurlHqipBUXARGpBRapi2dJWEfQp5Weyogc1pF/jVLqv8P2xQ8RaS/2OLFu6BelVMHX4Kf7n2m8eNkCTyprB7Wm35JKqWe8LUFE1gJPRXUMlpoM/dCKvro5EYo/pU66BoPBMJsJ9c+TfFSvwrKdSYQVh6jGP4qKVPkyE9tU7hT9TNdPkMKvfjcVID/1oGLY5iMIEoYYCBQv/vngF3+/x3tH8fHd+YyNfMSCggjR5NqmcqQcRHuK/i97KpVaeM8997B06VLq6+sZGxtjfHycrVu3IiLTlLqyUZjq7OyksbFxUkEItGIW4Cugk25rqw952fq1RSnFvffe67a95GIgQXzOJ/754FVvb28vbj5D7sIqtjiKRx/R2dmJiJBMJpmYmCAWiwXS6/Aqe9u2bX5jw297LI9xN0XtLBaL8dxzzwGEKvpSLPLZR6E0oj0lubVp2bJlDA4OTh5xneIdmZS6mpubWbBgweSafjdshSinglBtbS1jY2O+Ptn1Dg8PT1MI86Kurg6l1BTxjH379gFaeCPT9gMHfJ+tWVSyib+tG7BixQrmzp1bNJ/svnMqi9nqXl4+2yImueLWR08+qZ+ilK7CZo+L+vr6nMv22maPDb/tudju3bsXmK62F4/Hi6LqFxW8xrtXnIspNOWk6NMLXpeSIsKuXbtcFYLa29s9pwjcbLu6urjuuuuorq7O2vb48eOsXbuWioqKabZ+bYniZVyu8e/r62PDhg2uMczXJ7d6jx49ysaNG4sSS79pDb/xuG7dOtd6CzA2ctoexHbHjh2uymAzbXohn35w/Kao8Sh60q2urj5x7tw511OmcprT9WpLVVUV586dcy0vrDndYsU/H/zi39zcPCn5mIkozul6xdlvLtFv7FRXV18YHx/POKfrZwuza043n36AEu2npb4xGMeiCEuVKCcBlqqqqhO52hZK+MXZFtIWe3htC/NVqPjn88o2/sWMpbO8qqqqoULFws/nfMZONrZ++8lMF8DJJ5ZF8ynsoFiNvQP96G5BPwL8iqBBQC/xexRoRK8zvyZo8ICtwB7r/R7gxlIGPyov4P1o0ZdKtFCKrcZf1Digl6s+bL1/DmiPQvytsXgH8CpgbxR8yrM99WjxnFrg74GPlXubyvkV6n26Dm4GHlF6JPyX9Rml1HBA24et3z4M3BzQbtLWev8QWpMgaL0zCTuG54EfYgnNlCAOzvj/FxGIv4hUow/GP7Bey0RkQZmPiRuBx5VSZ9AHlGz2L0OBCT3pWsuC81EB+gBwLEdbZ70jwO9lYTsjEJFL0cIy9i0WJVFhytDvCq0MFzbXAweUUieUUufQV1GvDNelvHHG+cfARhGpC9Gf2U3Yp9rAW9Gao/afevOA88DSgPa/CVRY72uAc8C6AHbXWb+tsj5XUgZauEXqg7c53q9CC4LMLXKdbwBOO/r9EuCNEYjFHuAfHJ8/BXSH7Vce7akFzgCbHN89B/xl2L7N1lfoZ7pAHVqcw/6LdQgtrdcQxFgp9S2l9VdRSo2h9VC9b/DVNABdSp/NoJQ6r5T6p+xcnxkopb7p+NgDnEDvrMWkHi0MpCwfTiul/rXIdQZhHC2FaPMY4P2Xd7SpRM/nPu34bh9aKN4QAkbwxmAwGEpIFM50A1FMkZTZIgpihGYMhvApmzPdfBZD5Fv2TLmBvJgxzIfZEn+DAUJ4BHs+KkCdnZ1UVlZOindUVlbS19cHwB133AHoHTiXsvft25dRfKVcDkpBSY9hdXU1AwMDJBIJbrzxRsA9hvms1vFbDfb0009Pig/Z8W9ubmZ4uHh3Nfn55KXuZW0PZZWhF+WgsjXbKXnSzVUFaNu2bZMiKU7xDhGhurqa3t5eV1u7bK969+/fP0V8paamhrGxMbZt21bqEBWVdEGXWCxGVVUVc+fO5ciRI34xzFmBya/fd+/ePUW4yFY5W7VqVcHansknn/a6qntBaRSpsqUcVLZmO6E8QDEXpS6AxsZG3vnOd7qW62a7a9cu13ptmTuvcmcS73//+z23u8XQ7p988FL3Civ+fu11U6w6depUKP4GIeoqW7OdUJLuhg0b6O/vp66ujvPnz9Pd3U1VVRUAbW1tiAh1dXU0NTXR3d09KfHY0dGRUQHK1sFNtz1w4ADJZHJSrjC93qGhIU6fPu1Z9sDAzPoPx62d9jRNpvhXVlayaFH+T6xPj39fX9/kGa2bX/lKOfoxMTGR0a/KSr1rpMdjaGiIkZER2traiupXPrj5DO7tbWxsnEzMhuJS8qSbSCQGk8mk65xTMpl0tc00YEZHR0kmkyxatMjTNpeynTvfTCFTO7u6upgzZw5tbW2eMbIEcnLCq99heqI4ePAg8+fPZ968eblWGcin7du3e87pJpNJzznd4niWO3771/bt233ti+GX4SJlc/dCEFm+Ykn+xePxY351lwPFjGE+BPhDy/y5Y5gxlM19umNjY83WbUNXoledxYBPAl9SSolSSnLdMR1l/z3wEfRqnUFgmVJKZkLChSntfA2w03p/F/ChfGNYIL/uB94BJNCrqOaF5ZPBUCzKJuk6+ARabk9RQHEWpwCLUuoC8Eihyo4gHwN+br0vicCNHyJSiVbDekQpdRbYBbwiXK8MhsJTjkn3avRZKOg15E0isrgA5a5Ez3Hba9QjkYyKhH21AFrK8XoRKe6TKP3ZCDyvlDpqfZ7J8TfMYspmTtcNERkFHlNK5bWDikgHWjx9nvV5PfAL9CXuUN6ORhhrMcTnlVIfDdGHg0BMKbXc+vxatPZrldI6vwbDjGAm/DX/62jpunz5OFrT1WY/8CFgNgg9vxF9gAmT/8XFKxjQovIfMgnXMNMo+zNdg8FgKCciO6cbVUWscsMoeBkM0SKySddeF+/2WrJkCalUamEuCcUvESUSiRmT7L3i6BfDYrVzNsXfYEgn0nO6nZ2dJBIJWlpamJiYAODIkSMAvgI34C7eEUDopGjCL2HQ2dmJiJBMJpmYmCCRSNDd3R1EJKgo7QwS/3ITmjEYghLppGurir3wwgtTVMVs8hHv8BM6cdtuC7SUE+nKYkFiWOx2evUduIu2DA6aVaqG8iayf6SJiNq1a5erOMt1113nq3XrJn4dUDQ763KjiIioHTt2TIvh8ePHWb9+fSjtnE3xNxjSifSZ7pYtWzJ+f9lllwGwc+dOksnkpHhLU1PTpGLSnDlzPMt2s7UFbnp7e6dtE5FIq0u5cfvtt0/7zi+GtvpXsfDqO5gef1uJrhzjbzA4ifSZ7qOPPjptxxwdHaWuro5NmzZx9OhRzzLchFICCNx4KuyXkwCLiKienp4pMezq6qK+vp7Xv/71PP/88662xRL6mU3xNxjSiWzSjaoiVrlhFLwMhmgR2VvGrETwReD/2QpY9gu9Lv8DJln4Y8XoJUAfur9fBvw8TFUxg2E2E9kzXRF5C3A3cLlSajBtWzuwG9iilNobhn/lhIg8BixQSi0TkWrgBbRs5fGQXTMYZh2RPdMFVqElHDPdI/Qk+sztitK6VLbcBXwUQCk1DvwS+GCYDhkMs5XInukaioeI/ACtnnZV2L4YDLMNk3QNBoOhhER5esFgMBhmHKEm3XyUxIwKWWaMqpjBEG1CnV4QEdXR0UFNTQ3Nzc1MTExQWVnJwYMHSSQSKKXYvHmz61Lejo4OKisraWtrY2JigurqagYGBkilUqRSKbZv3z7rlotmiktlZSV9fX3ceuutOS8oMRgMhSH0pDs0NER9fT2nT5+mvr4+029ck26utjMZr7j4qac5fjOrYmYwlJLQtRcefPDBKQkgFotRUVFBU1MTS5Ysycq2traW4eFh1q5dy9y5c0vUgujhFlNwV/fau3cvV199dcieGwwzn9CTbiYJv/Pnz3P06FHfpJtue/nllzNv3jyeeeYZNm7cWHTfo4pbTMFfRMhgMBSX0KcXiiXP6GU7k/GKSzKZpLe3N+M2GzOnazAUl1DPdBOJxKDfUwASiURG1eqqqqohEfGcQ3Czncn4xSU9qYpIo1Jq2H4/NjY2G55+bDCERqi3jI2NjTVbZ6LvA+6z3j8FXGe9n+t21jU+Pj7P+s1bgQeAucBPgZuBubNVzMURlw7gFuB6oNstnnbCTX9vMBiKQ1QWR9wMPGK9/z7wDgicBG4GHrF++0PgbbM9eYhIG/BS4CfAY0BCRJbP9rgYDFEg9KQrIlXAjVxMuheA9wa0jQE3oaUeAc6gz3xnO+8BapVSY9YE7yPog5PBYAiZ0LUXROSPgE8qpeKO7+qVUqMBbN8PfEUpVZGt7UxG9JMn65RSp6zPfwZ82Bljg8EQDqHfMgZ0An/l/CKLpLkX+OscbWcs1tntKcdXdwPzQ3LHYDA4CP1M12AwGGYToc/pOslHrGW2Cr3M1nYbDOVKpM50/RY8eC12yMe2nJmt7TYYypWSz+n6PZ22s7NzikJWIpGgu7ubW2+9FdBJJhvbvr4+Tp8+XYSWRIf0dldXV3PgwAFEhHg87hkzswLNYCgtJU+6qVRq4Y4dO5g/X/+vY+sCDA4OcvXVV7N//37WrFnDoUOHqKioIBaLUVlZydGjR9m1axeDg4PTbI8fP8769etZs2YNDzzwAMPDw7S0tDA2NoaITCpozVQyxayuro6mpibOnj3rGjcr5p4rAg0GQ2Ep+fSC1+WwiLgmiNbWVvwuo91sh4aGaG9vn5GX2SKifJKqb9xmYlwMhqgSStLt6emhv79/8mysu7ubqqoqW7DczY5HH32UZDI5xfbkyZMsXryY+vr6WZlcgszpusW7ra3NPpjNuLgYDFGl5NMLiURiMJlMul7S9vb2TkkQo6OjpFIp2tra2L59u2fZmWxFhDlz5hS6GZFi586d0w5Gdtzi8TjJZNLVdjaKAhkMYRKpuxf8/mTz+tMnH9tyxq/d8Xj8mNd2g8FQWiJ1n65DdewnwKvRZ+JDQKufapjD9iHgDnTbDgOrZrLimKPd9wHvs94/CWxWSolJuAZDtIhU0gWtnYBWyNqplJoAfoAWtQliGwduAH5gTXQ+zCwQenEI/9iiQQ8TMGYGg6G0RC7pAm8A9iilzlifv299F4TXAc8opYasz48AtxfYvyiyDXhRKXXI+vwIcKslfGMwGCJEpOZ0AUSkDzillHqJ9fkW4L+ACqXUBR/bp9HqWoutz5uAx4EapVSquJ6Hh4jsBNYrpS61Pi8BeoBFSinvZ64bDIaSEsWkuwAYUUqddXy3WCnVF8B2HjDmOEsObFvOiMilAEqpEcd3M77dBkM5ErmkazAYDDOZKM7pGgwGw4wl1KTrJ0uYSCRy2hZke7lKHuYTs3Jut8EwUwh1esFewnrvvfeydOlS6uvrGRsbY3x8nK1btyIi3HPPPa7bcrW16i7L5a9BYhZge9m122CYKYT+uJ6Ojg7q6upQSjEyMjIp1nLgwAEAli1bxuDg4KSuwqpVqzh8+HBetqdOncrgSfng12637U8++WTInhsMhkic6Xps9xTAydXWsb3szvjyiZlje9m122CYKYR6pptIJAZFxHWZalVVFW7391vi3K5le9nadWfhamTIJ2a2fVEcMxgMgYjcLWMi0qiUGk5/77ctX9tyZra222AoRyKXdA0Gg2EmY+7TNRgMhhJikq7BYDCUEJN0DQaDoYSYpGswGAwlxCRdg8FgKCEm6RoMBkMJMUnXYDAYSohJugaDwVBCTNI1GAyGEvL/AZHFmqoSA2z0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(clf)\n",
    "\n",
    "\n",
    "# from sklearn.tree import plot_tree\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(70, 50))\n",
    "\n",
    "# plot_tree(clf, filled=True)\n",
    "# plt.title(\"Decision tree trained on all the iris features\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Classification\n",
    "\n",
    "KNN is one of the simplest and widely used classification algorithms in which a new data point is classified based on similarity in the specific group of neighboring data points. For a given data point in the set, the algorithms find the distances between this and all other K numbers of datapoint in the dataset close to the initial point and votes for that category that has the most frequency. Usually, Euclidean distance is taking as a measure of distance.\n",
    "\n",
    "Step 1: Select the value of K neighbors(say k=5)\n",
    "\n",
    " \n",
    "\n",
    "Step 2: Find the K (5) nearest data point for our new data point based on euclidean distance\n",
    "\n",
    " \n",
    "\n",
    "Step 3: Among these K data points count the data points in each category\n",
    "\n",
    " \n",
    "\n",
    "Step 4: Assign the new data point to the category that has the most neighbors of the new datapoint\n",
    "\n",
    "![](images/8.jpg)\n",
    "\n",
    "\n",
    "Choosing the optimal value for K is best done by first inspecting the data. In general, a large K value is more precise as it reduces the overall noise but there is no guarantee. Generally we can use the Square root of the number of samples in the dataset as value for K. Historically, the optimal K for most datasets has been between 3-10. That produces much better results than 1NN.\n",
    "\n",
    "### Standardized Distance\t\t\n",
    "One major drawback in calculating distance measures directly from the training set is in the case where variables have different measurement scales or there is a mixture of numerical and categorical variables. For example, if one variable is based on annual income in dollars, and the other is based on age in years then income will have a much higher influence on the distance calculated. One solution is to standardize the training set using feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.7058823529411765\n",
      "Recall: 0.5647058823529412\n",
      "F1-Score: 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# Import KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    " \n",
    "# Create a KNN classifier object\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    " \n",
    "# Train the model using the training dataset\n",
    "model.fit(feature_train,target_train)\n",
    " \n",
    "# Predict the target variable for test dataset\n",
    "predictions = model.predict(feature_test)\n",
    " \n",
    "# Import metrics module for performance evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    " \n",
    "# Calculate model accuracy\n",
    "print(\"Accuracy:\",accuracy_score(target_test, predictions))\n",
    "# Calculate model precision\n",
    "print(\"Precision:\",precision_score(target_test, predictions))\n",
    "# Calculate model recall\n",
    "print(\"Recall:\",recall_score(target_test, predictions))\n",
    "# Calculate model f1 score\n",
    "print(\"F1-Score:\",f1_score(target_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
